{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('./input/train.json')\n",
    "test = pd.read_json(\"./input/test.json\")\n",
    "combined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_enc = preprocessing.LabelEncoder()\n",
    "building_enc.fit(combined.building_id)\n",
    "\n",
    "manager_enc = preprocessing.LabelEncoder()\n",
    "manager_enc.fit(combined.manager_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['building_enc'] = building_enc.transform(combined.building_id)\n",
    "combined['manager_enc'] = manager_enc.transform(combined.manager_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['bathrooms', \\\n",
    "                'bedrooms', \\\n",
    "                'price', \\\n",
    "                'latitude', \\\n",
    "                'longitude', \\\n",
    "                'building_enc', \\\n",
    "                'manager_enc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = combined[~pd.isnull(combined.interest_level)]\n",
    "test = combined[pd.isnull(combined.interest_level)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\\\n",
    "    train[feature_list], \\\n",
    "    train[['interest_level']].values, \\\n",
    "    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train[:,0])\n",
    "y_train_encoded = le.transform(y_train[:,0])\n",
    "y_validate_encoded = le.transform(y_validate[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded)\n",
    "dvalidate = xgb.DMatrix(X_validate, label=y_validate_encoded)\n",
    "evallist  = [(dvalidate,'eval'), (dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.293486\ttrain-merror:0.281385\n",
      "[1]\teval-merror:0.290354\ttrain-merror:0.278724\n",
      "[2]\teval-merror:0.28974\ttrain-merror:0.277998\n",
      "[3]\teval-merror:0.289924\ttrain-merror:0.278119\n",
      "[4]\teval-merror:0.288881\ttrain-merror:0.277212\n",
      "[5]\teval-merror:0.28931\ttrain-merror:0.277333\n",
      "[6]\teval-merror:0.288696\ttrain-merror:0.27576\n",
      "[7]\teval-merror:0.288758\ttrain-merror:0.275336\n",
      "[8]\teval-merror:0.286855\ttrain-merror:0.273794\n",
      "[9]\teval-merror:0.286977\ttrain-merror:0.272433\n",
      "[10]\teval-merror:0.284951\ttrain-merror:0.26956\n",
      "[11]\teval-merror:0.283907\ttrain-merror:0.268199\n",
      "[12]\teval-merror:0.285135\ttrain-merror:0.267534\n",
      "[13]\teval-merror:0.284092\ttrain-merror:0.267352\n",
      "[14]\teval-merror:0.282986\ttrain-merror:0.265296\n",
      "[15]\teval-merror:0.283416\ttrain-merror:0.263844\n",
      "[16]\teval-merror:0.282004\ttrain-merror:0.262271\n",
      "[17]\teval-merror:0.280899\ttrain-merror:0.260578\n",
      "[18]\teval-merror:0.28053\ttrain-merror:0.259459\n",
      "[19]\teval-merror:0.280469\ttrain-merror:0.257584\n",
      "[20]\teval-merror:0.280223\ttrain-merror:0.256465\n",
      "[21]\teval-merror:0.280408\ttrain-merror:0.255134\n",
      "[22]\teval-merror:0.279364\ttrain-merror:0.25468\n",
      "[23]\teval-merror:0.279548\ttrain-merror:0.252593\n",
      "[24]\teval-merror:0.279978\ttrain-merror:0.251263\n",
      "[25]\teval-merror:0.27918\ttrain-merror:0.250446\n",
      "[26]\teval-merror:0.278689\ttrain-merror:0.249962\n",
      "[27]\teval-merror:0.278259\ttrain-merror:0.248783\n",
      "[28]\teval-merror:0.278443\ttrain-merror:0.246877\n",
      "[29]\teval-merror:0.278627\ttrain-merror:0.246121\n",
      "[30]\teval-merror:0.27918\ttrain-merror:0.245002\n",
      "[31]\teval-merror:0.278259\ttrain-merror:0.243762\n",
      "[32]\teval-merror:0.278136\ttrain-merror:0.243278\n",
      "[33]\teval-merror:0.277952\ttrain-merror:0.242522\n",
      "[34]\teval-merror:0.276601\ttrain-merror:0.241675\n",
      "[35]\teval-merror:0.275987\ttrain-merror:0.240254\n",
      "[36]\teval-merror:0.274698\ttrain-merror:0.239589\n",
      "[37]\teval-merror:0.275373\ttrain-merror:0.237986\n",
      "[38]\teval-merror:0.274943\ttrain-merror:0.236958\n",
      "[39]\teval-merror:0.274513\ttrain-merror:0.235869\n",
      "[40]\teval-merror:0.27482\ttrain-merror:0.234659\n",
      "[41]\teval-merror:0.274391\ttrain-merror:0.233963\n",
      "[42]\teval-merror:0.274452\ttrain-merror:0.233691\n",
      "[43]\teval-merror:0.274513\ttrain-merror:0.232935\n",
      "[44]\teval-merror:0.274698\ttrain-merror:0.231604\n",
      "[45]\teval-merror:0.274698\ttrain-merror:0.230274\n",
      "[46]\teval-merror:0.274084\ttrain-merror:0.229608\n",
      "[47]\teval-merror:0.273838\ttrain-merror:0.229306\n",
      "[48]\teval-merror:0.272856\ttrain-merror:0.227975\n",
      "[49]\teval-merror:0.272549\ttrain-merror:0.226342\n",
      "[50]\teval-merror:0.271873\ttrain-merror:0.225586\n",
      "[51]\teval-merror:0.272426\ttrain-merror:0.224013\n",
      "[52]\teval-merror:0.272426\ttrain-merror:0.22365\n",
      "[53]\teval-merror:0.272364\ttrain-merror:0.222834\n",
      "[54]\teval-merror:0.271443\ttrain-merror:0.222652\n",
      "[55]\teval-merror:0.271505\ttrain-merror:0.221927\n",
      "[56]\teval-merror:0.270829\ttrain-merror:0.220263\n",
      "[57]\teval-merror:0.270216\ttrain-merror:0.218811\n",
      "[58]\teval-merror:0.2704\ttrain-merror:0.217753\n",
      "[59]\teval-merror:0.270031\ttrain-merror:0.216755\n",
      "[60]\teval-merror:0.271136\ttrain-merror:0.21618\n",
      "[61]\teval-merror:0.270584\ttrain-merror:0.215243\n",
      "[62]\teval-merror:0.270707\ttrain-merror:0.21494\n",
      "[63]\teval-merror:0.270338\ttrain-merror:0.214487\n",
      "[64]\teval-merror:0.270461\ttrain-merror:0.2137\n",
      "[65]\teval-merror:0.2704\ttrain-merror:0.212823\n",
      "[66]\teval-merror:0.269786\ttrain-merror:0.211462\n",
      "[67]\teval-merror:0.270154\ttrain-merror:0.211039\n",
      "[68]\teval-merror:0.269724\ttrain-merror:0.209678\n",
      "[69]\teval-merror:0.269663\ttrain-merror:0.208982\n",
      "[70]\teval-merror:0.269909\ttrain-merror:0.208256\n",
      "[71]\teval-merror:0.270031\ttrain-merror:0.207319\n",
      "[72]\teval-merror:0.2704\ttrain-merror:0.205867\n",
      "[73]\teval-merror:0.269724\ttrain-merror:0.204264\n",
      "[74]\teval-merror:0.268128\ttrain-merror:0.203266\n",
      "[75]\teval-merror:0.267575\ttrain-merror:0.202964\n",
      "[76]\teval-merror:0.267637\ttrain-merror:0.202419\n",
      "[77]\teval-merror:0.266716\ttrain-merror:0.201724\n",
      "[78]\teval-merror:0.26647\ttrain-merror:0.200756\n",
      "[79]\teval-merror:0.266654\ttrain-merror:0.200181\n",
      "[80]\teval-merror:0.266716\ttrain-merror:0.199607\n",
      "[81]\teval-merror:0.267637\ttrain-merror:0.199425\n",
      "[82]\teval-merror:0.266716\ttrain-merror:0.198185\n",
      "[83]\teval-merror:0.266225\ttrain-merror:0.197369\n",
      "[84]\teval-merror:0.265918\ttrain-merror:0.196673\n",
      "[85]\teval-merror:0.265672\ttrain-merror:0.196038\n",
      "[86]\teval-merror:0.265672\ttrain-merror:0.195252\n",
      "[87]\teval-merror:0.265918\ttrain-merror:0.194707\n",
      "[88]\teval-merror:0.265304\ttrain-merror:0.193619\n",
      "[89]\teval-merror:0.265733\ttrain-merror:0.193195\n",
      "[90]\teval-merror:0.265549\ttrain-merror:0.192197\n",
      "[91]\teval-merror:0.265979\ttrain-merror:0.191834\n",
      "[92]\teval-merror:0.266163\ttrain-merror:0.19126\n",
      "[93]\teval-merror:0.265856\ttrain-merror:0.190746\n",
      "[94]\teval-merror:0.265488\ttrain-merror:0.189868\n",
      "[95]\teval-merror:0.265856\ttrain-merror:0.189143\n",
      "[96]\teval-merror:0.265918\ttrain-merror:0.187993\n",
      "[97]\teval-merror:0.26604\ttrain-merror:0.187721\n",
      "[98]\teval-merror:0.265795\ttrain-merror:0.187237\n",
      "[99]\teval-merror:0.265672\ttrain-merror:0.186663\n"
     ]
    }
   ],
   "source": [
    "param = {'bst:max_depth':8, \\\n",
    "         'bst:eta':0.3, \\\n",
    "         'silent':1,\n",
    "         'objective':'multi:softprob',\n",
    "         'num_class':3}\n",
    "\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round, evallist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.601153511921\n"
     ]
    }
   ],
   "source": [
    "predict_validate = bst.predict(dvalidate)\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y_validate, predict_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03644914,  0.65130293,  0.31224793],\n",
       "       [ 0.10931576,  0.82827348,  0.06241076],\n",
       "       [ 0.02048757,  0.85013294,  0.12937947],\n",
       "       ..., \n",
       "       [ 0.08967831,  0.666933  ,  0.24338867],\n",
       "       [ 0.22634688,  0.44596496,  0.32768816],\n",
       "       [ 0.03851657,  0.77377886,  0.18770459]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(test[feature_list])\n",
    "test_predict = bst.predict(dtest)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.036449</td>\n",
       "      <td>0.651303</td>\n",
       "      <td>0.312248</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109316</td>\n",
       "      <td>0.828273</td>\n",
       "      <td>0.062411</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.850133</td>\n",
       "      <td>0.129379</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081615</td>\n",
       "      <td>0.516072</td>\n",
       "      <td>0.402313</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.894749</td>\n",
       "      <td>0.094472</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.977479</td>\n",
       "      <td>0.021824</td>\n",
       "      <td>6840081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.097035</td>\n",
       "      <td>0.620584</td>\n",
       "      <td>0.282381</td>\n",
       "      <td>6922337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.028749</td>\n",
       "      <td>0.362738</td>\n",
       "      <td>0.608513</td>\n",
       "      <td>6913616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.124624</td>\n",
       "      <td>0.437174</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>6937820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.233752</td>\n",
       "      <td>0.336261</td>\n",
       "      <td>0.429987</td>\n",
       "      <td>6893933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.972083</td>\n",
       "      <td>0.022521</td>\n",
       "      <td>6832604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.117467</td>\n",
       "      <td>0.535792</td>\n",
       "      <td>0.346741</td>\n",
       "      <td>6915282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.020549</td>\n",
       "      <td>0.865048</td>\n",
       "      <td>0.114404</td>\n",
       "      <td>7127565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.050661</td>\n",
       "      <td>0.870175</td>\n",
       "      <td>0.079164</td>\n",
       "      <td>6827899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.007629</td>\n",
       "      <td>0.867923</td>\n",
       "      <td>0.124448</td>\n",
       "      <td>6934855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.021320</td>\n",
       "      <td>0.765319</td>\n",
       "      <td>0.213361</td>\n",
       "      <td>6861826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.041995</td>\n",
       "      <td>0.557415</td>\n",
       "      <td>0.400590</td>\n",
       "      <td>6871643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.920019</td>\n",
       "      <td>0.075900</td>\n",
       "      <td>6842542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.003929</td>\n",
       "      <td>0.945989</td>\n",
       "      <td>0.050082</td>\n",
       "      <td>6934145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.221027</td>\n",
       "      <td>0.297899</td>\n",
       "      <td>0.481074</td>\n",
       "      <td>6829365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.063074</td>\n",
       "      <td>0.643916</td>\n",
       "      <td>0.293010</td>\n",
       "      <td>7167858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.010802</td>\n",
       "      <td>0.941847</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>6859483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.084191</td>\n",
       "      <td>0.777733</td>\n",
       "      <td>0.138077</td>\n",
       "      <td>6861377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.059032</td>\n",
       "      <td>0.490905</td>\n",
       "      <td>0.450064</td>\n",
       "      <td>6848960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.962825</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>6918850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.138840</td>\n",
       "      <td>0.336309</td>\n",
       "      <td>0.524851</td>\n",
       "      <td>6916867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.006101</td>\n",
       "      <td>0.850038</td>\n",
       "      <td>0.143861</td>\n",
       "      <td>6895840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.546693</td>\n",
       "      <td>0.156870</td>\n",
       "      <td>0.296437</td>\n",
       "      <td>6813539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.036338</td>\n",
       "      <td>0.806026</td>\n",
       "      <td>0.157636</td>\n",
       "      <td>7116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.011321</td>\n",
       "      <td>0.942779</td>\n",
       "      <td>0.045899</td>\n",
       "      <td>6890328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74629</th>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.509810</td>\n",
       "      <td>0.404824</td>\n",
       "      <td>6855560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74630</th>\n",
       "      <td>0.257908</td>\n",
       "      <td>0.293007</td>\n",
       "      <td>0.449085</td>\n",
       "      <td>6816731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74631</th>\n",
       "      <td>0.023126</td>\n",
       "      <td>0.916035</td>\n",
       "      <td>0.060838</td>\n",
       "      <td>6925764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74632</th>\n",
       "      <td>0.036681</td>\n",
       "      <td>0.783120</td>\n",
       "      <td>0.180199</td>\n",
       "      <td>7139280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74633</th>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.470533</td>\n",
       "      <td>0.524239</td>\n",
       "      <td>6913068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74634</th>\n",
       "      <td>0.027025</td>\n",
       "      <td>0.867949</td>\n",
       "      <td>0.105026</td>\n",
       "      <td>6828445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74635</th>\n",
       "      <td>0.069443</td>\n",
       "      <td>0.737345</td>\n",
       "      <td>0.193212</td>\n",
       "      <td>6867865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74636</th>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.941280</td>\n",
       "      <td>0.056183</td>\n",
       "      <td>6820397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74637</th>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.889168</td>\n",
       "      <td>0.100696</td>\n",
       "      <td>6852197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74638</th>\n",
       "      <td>0.067894</td>\n",
       "      <td>0.438926</td>\n",
       "      <td>0.493180</td>\n",
       "      <td>7122934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74639</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.957797</td>\n",
       "      <td>0.042138</td>\n",
       "      <td>6907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74640</th>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.951414</td>\n",
       "      <td>0.046544</td>\n",
       "      <td>6865896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74641</th>\n",
       "      <td>0.202744</td>\n",
       "      <td>0.340421</td>\n",
       "      <td>0.456835</td>\n",
       "      <td>6840250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74642</th>\n",
       "      <td>0.013840</td>\n",
       "      <td>0.869046</td>\n",
       "      <td>0.117114</td>\n",
       "      <td>6926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74643</th>\n",
       "      <td>0.043106</td>\n",
       "      <td>0.811008</td>\n",
       "      <td>0.145885</td>\n",
       "      <td>6893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74644</th>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.959207</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>6867538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74645</th>\n",
       "      <td>0.292354</td>\n",
       "      <td>0.285179</td>\n",
       "      <td>0.422467</td>\n",
       "      <td>6884360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74646</th>\n",
       "      <td>0.124374</td>\n",
       "      <td>0.610902</td>\n",
       "      <td>0.264724</td>\n",
       "      <td>6903964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74647</th>\n",
       "      <td>0.046553</td>\n",
       "      <td>0.733086</td>\n",
       "      <td>0.220361</td>\n",
       "      <td>6907851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74648</th>\n",
       "      <td>0.085007</td>\n",
       "      <td>0.497636</td>\n",
       "      <td>0.417357</td>\n",
       "      <td>7211166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74649</th>\n",
       "      <td>0.121018</td>\n",
       "      <td>0.386773</td>\n",
       "      <td>0.492209</td>\n",
       "      <td>6844290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74650</th>\n",
       "      <td>0.214633</td>\n",
       "      <td>0.460994</td>\n",
       "      <td>0.324373</td>\n",
       "      <td>6947597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74651</th>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.576893</td>\n",
       "      <td>0.422951</td>\n",
       "      <td>6895423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74652</th>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.965742</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>6812077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74653</th>\n",
       "      <td>0.002546</td>\n",
       "      <td>0.970205</td>\n",
       "      <td>0.027249</td>\n",
       "      <td>6903956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74654</th>\n",
       "      <td>0.136290</td>\n",
       "      <td>0.781816</td>\n",
       "      <td>0.081893</td>\n",
       "      <td>6881005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74655</th>\n",
       "      <td>0.001482</td>\n",
       "      <td>0.971265</td>\n",
       "      <td>0.027253</td>\n",
       "      <td>6835379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74656</th>\n",
       "      <td>0.089678</td>\n",
       "      <td>0.666933</td>\n",
       "      <td>0.243389</td>\n",
       "      <td>6882352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74657</th>\n",
       "      <td>0.226347</td>\n",
       "      <td>0.445965</td>\n",
       "      <td>0.327688</td>\n",
       "      <td>6884758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74658</th>\n",
       "      <td>0.038517</td>\n",
       "      <td>0.773779</td>\n",
       "      <td>0.187705</td>\n",
       "      <td>6924212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           high       low    medium  listing_id\n",
       "0      0.036449  0.651303  0.312248     7142618\n",
       "1      0.109316  0.828273  0.062411     7210040\n",
       "2      0.020488  0.850133  0.129379     7103890\n",
       "3      0.081615  0.516072  0.402313     7143442\n",
       "4      0.010779  0.894749  0.094472     6860601\n",
       "5      0.000697  0.977479  0.021824     6840081\n",
       "6      0.097035  0.620584  0.282381     6922337\n",
       "7      0.028749  0.362738  0.608513     6913616\n",
       "8      0.124624  0.437174  0.438202     6937820\n",
       "9      0.233752  0.336261  0.429987     6893933\n",
       "10     0.005396  0.972083  0.022521     6832604\n",
       "11     0.117467  0.535792  0.346741     6915282\n",
       "12     0.020549  0.865048  0.114404     7127565\n",
       "13     0.050661  0.870175  0.079164     6827899\n",
       "14     0.007629  0.867923  0.124448     6934855\n",
       "15     0.021320  0.765319  0.213361     6861826\n",
       "16     0.041995  0.557415  0.400590     6871643\n",
       "17     0.004081  0.920019  0.075900     6842542\n",
       "18     0.003929  0.945989  0.050082     6934145\n",
       "19     0.221027  0.297899  0.481074     6829365\n",
       "20     0.063074  0.643916  0.293010     7167858\n",
       "21     0.010802  0.941847  0.047351     6859483\n",
       "22     0.084191  0.777733  0.138077     6861377\n",
       "23     0.059032  0.490905  0.450064     6848960\n",
       "24     0.004317  0.962825  0.032858     6918850\n",
       "25     0.138840  0.336309  0.524851     6916867\n",
       "26     0.006101  0.850038  0.143861     6895840\n",
       "27     0.546693  0.156870  0.296437     6813539\n",
       "28     0.036338  0.806026  0.157636     7116900\n",
       "29     0.011321  0.942779  0.045899     6890328\n",
       "...         ...       ...       ...         ...\n",
       "74629  0.085366  0.509810  0.404824     6855560\n",
       "74630  0.257908  0.293007  0.449085     6816731\n",
       "74631  0.023126  0.916035  0.060838     6925764\n",
       "74632  0.036681  0.783120  0.180199     7139280\n",
       "74633  0.005228  0.470533  0.524239     6913068\n",
       "74634  0.027025  0.867949  0.105026     6828445\n",
       "74635  0.069443  0.737345  0.193212     6867865\n",
       "74636  0.002536  0.941280  0.056183     6820397\n",
       "74637  0.010135  0.889168  0.100696     6852197\n",
       "74638  0.067894  0.438926  0.493180     7122934\n",
       "74639  0.000064  0.957797  0.042138     6907838\n",
       "74640  0.002042  0.951414  0.046544     6865896\n",
       "74641  0.202744  0.340421  0.456835     6840250\n",
       "74642  0.013840  0.869046  0.117114     6926011\n",
       "74643  0.043106  0.811008  0.145885     6893100\n",
       "74644  0.000812  0.959207  0.039982     6867538\n",
       "74645  0.292354  0.285179  0.422467     6884360\n",
       "74646  0.124374  0.610902  0.264724     6903964\n",
       "74647  0.046553  0.733086  0.220361     6907851\n",
       "74648  0.085007  0.497636  0.417357     7211166\n",
       "74649  0.121018  0.386773  0.492209     6844290\n",
       "74650  0.214633  0.460994  0.324373     6947597\n",
       "74651  0.000155  0.576893  0.422951     6895423\n",
       "74652  0.006196  0.965742  0.028062     6812077\n",
       "74653  0.002546  0.970205  0.027249     6903956\n",
       "74654  0.136290  0.781816  0.081893     6881005\n",
       "74655  0.001482  0.971265  0.027253     6835379\n",
       "74656  0.089678  0.666933  0.243389     6882352\n",
       "74657  0.226347  0.445965  0.327688     6884758\n",
       "74658  0.038517  0.773779  0.187705     6924212\n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame = pd.DataFrame(test_predict)\n",
    "result_frame.columns = le.classes_\n",
    "result_frame['listing_id'] = test.listing_id.reset_index().listing_id\n",
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not submitted\n",
    "result_frame[['listing_id','high','medium','low']].to_csv('ManagerBuilding-result.csv', \\\n",
    "                                                          index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
