{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kevin/anaconda3/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('./input/train.json')\n",
    "test = pd.read_json(\"./input/test.json\")\n",
    "combined = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_enc = preprocessing.LabelEncoder()\n",
    "building_enc.fit(combined.building_id)\n",
    "\n",
    "manager_enc = preprocessing.LabelEncoder()\n",
    "manager_enc.fit(combined.manager_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['building_enc'] = building_enc.transform(combined.building_id)\n",
    "combined['manager_enc'] = manager_enc.transform(combined.manager_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['n_photo'] = combined.photos.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['bathrooms', \\\n",
    "                'bedrooms', \\\n",
    "                'price', \\\n",
    "                'latitude', \\\n",
    "                'longitude', \\\n",
    "                'building_enc', \\\n",
    "                'manager_enc', \\\n",
    "                'n_photo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = combined[~pd.isnull(combined.interest_level)]\n",
    "test = combined[pd.isnull(combined.interest_level)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validate, y_train, y_validate = train_test_split(\\\n",
    "    train[feature_list], \\\n",
    "    train[['interest_level']].values, \\\n",
    "    test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y_train[:,0])\n",
    "y_train_encoded = le.transform(y_train[:,0])\n",
    "y_validate_encoded = le.transform(y_validate[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train_encoded)\n",
    "dvalidate = xgb.DMatrix(X_validate, label=y_validate_encoded)\n",
    "evallist  = [(dvalidate,'eval'), (dtrain,'train')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-merror:0.294222\ttrain-merror:0.283472\n",
      "[1]\teval-merror:0.288635\ttrain-merror:0.277937\n",
      "[2]\teval-merror:0.290047\ttrain-merror:0.278663\n",
      "[3]\teval-merror:0.288144\ttrain-merror:0.277272\n",
      "[4]\teval-merror:0.288267\ttrain-merror:0.276879\n",
      "[5]\teval-merror:0.287898\ttrain-merror:0.27697\n",
      "[6]\teval-merror:0.287776\ttrain-merror:0.275941\n",
      "[7]\teval-merror:0.287284\ttrain-merror:0.274974\n",
      "[8]\teval-merror:0.287039\ttrain-merror:0.274792\n",
      "[9]\teval-merror:0.287162\ttrain-merror:0.273129\n",
      "[10]\teval-merror:0.285197\ttrain-merror:0.271012\n",
      "[11]\teval-merror:0.283907\ttrain-merror:0.26962\n",
      "[12]\teval-merror:0.284706\ttrain-merror:0.268471\n",
      "[13]\teval-merror:0.284583\ttrain-merror:0.266959\n",
      "[14]\teval-merror:0.284092\ttrain-merror:0.266203\n",
      "[15]\teval-merror:0.283171\ttrain-merror:0.265084\n",
      "[16]\teval-merror:0.282188\ttrain-merror:0.263421\n",
      "[17]\teval-merror:0.281513\ttrain-merror:0.261364\n",
      "[18]\teval-merror:0.281267\ttrain-merror:0.260275\n",
      "[19]\teval-merror:0.281022\ttrain-merror:0.259126\n",
      "[20]\teval-merror:0.280837\ttrain-merror:0.256646\n",
      "[21]\teval-merror:0.279732\ttrain-merror:0.25589\n",
      "[22]\teval-merror:0.27918\ttrain-merror:0.254529\n",
      "[23]\teval-merror:0.277829\ttrain-merror:0.251716\n",
      "[24]\teval-merror:0.277952\ttrain-merror:0.251081\n",
      "[25]\teval-merror:0.277338\ttrain-merror:0.249206\n",
      "[26]\teval-merror:0.277522\ttrain-merror:0.247392\n",
      "[27]\teval-merror:0.276294\ttrain-merror:0.245607\n",
      "[28]\teval-merror:0.275803\ttrain-merror:0.244488\n",
      "[29]\teval-merror:0.275005\ttrain-merror:0.243309\n",
      "[30]\teval-merror:0.274943\ttrain-merror:0.241403\n",
      "[31]\teval-merror:0.273777\ttrain-merror:0.240617\n",
      "[32]\teval-merror:0.273961\ttrain-merror:0.239528\n",
      "[33]\teval-merror:0.273777\ttrain-merror:0.239044\n",
      "[34]\teval-merror:0.273408\ttrain-merror:0.238288\n",
      "[35]\teval-merror:0.273654\ttrain-merror:0.237623\n",
      "[36]\teval-merror:0.272978\ttrain-merror:0.236262\n",
      "[37]\teval-merror:0.27261\ttrain-merror:0.234417\n",
      "[38]\teval-merror:0.272794\ttrain-merror:0.233449\n",
      "[39]\teval-merror:0.273101\ttrain-merror:0.232572\n",
      "[40]\teval-merror:0.272303\ttrain-merror:0.23103\n",
      "[41]\teval-merror:0.272549\ttrain-merror:0.230062\n",
      "[42]\teval-merror:0.272794\ttrain-merror:0.229155\n",
      "[43]\teval-merror:0.272426\ttrain-merror:0.22855\n",
      "[44]\teval-merror:0.273224\ttrain-merror:0.228066\n",
      "[45]\teval-merror:0.273347\ttrain-merror:0.227401\n",
      "[46]\teval-merror:0.273408\ttrain-merror:0.226342\n",
      "[47]\teval-merror:0.271996\ttrain-merror:0.225344\n",
      "[48]\teval-merror:0.271935\ttrain-merror:0.224406\n",
      "[49]\teval-merror:0.271689\ttrain-merror:0.223983\n",
      "[50]\teval-merror:0.270952\ttrain-merror:0.22241\n",
      "[51]\teval-merror:0.270952\ttrain-merror:0.221533\n",
      "[52]\teval-merror:0.270154\ttrain-merror:0.220687\n",
      "[53]\teval-merror:0.270523\ttrain-merror:0.220051\n",
      "[54]\teval-merror:0.270768\ttrain-merror:0.219809\n",
      "[55]\teval-merror:0.271198\ttrain-merror:0.218842\n",
      "[56]\teval-merror:0.271014\ttrain-merror:0.217239\n",
      "[57]\teval-merror:0.270338\ttrain-merror:0.215575\n",
      "[58]\teval-merror:0.269663\ttrain-merror:0.214396\n",
      "[59]\teval-merror:0.270031\ttrain-merror:0.212793\n",
      "[60]\teval-merror:0.270707\ttrain-merror:0.21237\n",
      "[61]\teval-merror:0.270584\ttrain-merror:0.211704\n",
      "[62]\teval-merror:0.270645\ttrain-merror:0.210978\n",
      "[63]\teval-merror:0.270154\ttrain-merror:0.209557\n",
      "[64]\teval-merror:0.269172\ttrain-merror:0.208347\n",
      "[65]\teval-merror:0.269356\ttrain-merror:0.207379\n",
      "[66]\teval-merror:0.269602\ttrain-merror:0.20623\n",
      "[67]\teval-merror:0.268312\ttrain-merror:0.205293\n",
      "[68]\teval-merror:0.268681\ttrain-merror:0.204022\n",
      "[69]\teval-merror:0.268251\ttrain-merror:0.203115\n",
      "[70]\teval-merror:0.267944\ttrain-merror:0.202692\n",
      "[71]\teval-merror:0.268005\ttrain-merror:0.202026\n",
      "[72]\teval-merror:0.267698\ttrain-merror:0.201482\n",
      "[73]\teval-merror:0.267698\ttrain-merror:0.200907\n",
      "[74]\teval-merror:0.267514\ttrain-merror:0.200091\n",
      "[75]\teval-merror:0.267944\ttrain-merror:0.199425\n",
      "[76]\teval-merror:0.267944\ttrain-merror:0.198821\n",
      "[77]\teval-merror:0.267207\ttrain-merror:0.197883\n",
      "[78]\teval-merror:0.266777\ttrain-merror:0.196855\n",
      "[79]\teval-merror:0.2669\ttrain-merror:0.195675\n",
      "[80]\teval-merror:0.266409\ttrain-merror:0.194828\n",
      "[81]\teval-merror:0.26604\ttrain-merror:0.193709\n",
      "[82]\teval-merror:0.265979\ttrain-merror:0.193286\n",
      "[83]\teval-merror:0.265365\ttrain-merror:0.192832\n",
      "[84]\teval-merror:0.265549\ttrain-merror:0.192106\n",
      "[85]\teval-merror:0.26604\ttrain-merror:0.191139\n",
      "[86]\teval-merror:0.26604\ttrain-merror:0.190927\n",
      "[87]\teval-merror:0.265304\ttrain-merror:0.190262\n",
      "[88]\teval-merror:0.266409\ttrain-merror:0.189264\n",
      "[89]\teval-merror:0.266347\ttrain-merror:0.18884\n",
      "[90]\teval-merror:0.26604\ttrain-merror:0.188175\n",
      "[91]\teval-merror:0.265856\ttrain-merror:0.187509\n",
      "[92]\teval-merror:0.265611\ttrain-merror:0.187298\n",
      "[93]\teval-merror:0.265242\ttrain-merror:0.185846\n",
      "[94]\teval-merror:0.264997\ttrain-merror:0.185271\n",
      "[95]\teval-merror:0.264812\ttrain-merror:0.18509\n",
      "[96]\teval-merror:0.264567\ttrain-merror:0.184546\n",
      "[97]\teval-merror:0.26469\ttrain-merror:0.18385\n",
      "[98]\teval-merror:0.264383\ttrain-merror:0.183094\n",
      "[99]\teval-merror:0.26426\ttrain-merror:0.182187\n"
     ]
    }
   ],
   "source": [
    "param = {'bst:max_depth':8, \\\n",
    "         'bst:eta':0.3, \\\n",
    "         'silent':1,\n",
    "         'objective':'multi:softprob',\n",
    "         'num_class':3}\n",
    "\n",
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round, evallist )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.596195830965\n"
     ]
    }
   ],
   "source": [
    "predict_validate = bst.predict(dvalidate)\n",
    "from sklearn.metrics import log_loss\n",
    "print(log_loss(y_validate, predict_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06094936,  0.54898244,  0.3900682 ],\n",
       "       [ 0.04651337,  0.85233468,  0.10115199],\n",
       "       [ 0.02391572,  0.79791516,  0.17816912],\n",
       "       ..., \n",
       "       [ 0.06407378,  0.80704117,  0.128885  ],\n",
       "       [ 0.22393315,  0.42850924,  0.3475576 ],\n",
       "       [ 0.04447626,  0.74955338,  0.20597033]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest = xgb.DMatrix(test[feature_list])\n",
    "test_predict = bst.predict(dtest)\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>medium</th>\n",
       "      <th>listing_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060949</td>\n",
       "      <td>0.548982</td>\n",
       "      <td>0.390068</td>\n",
       "      <td>7142618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046513</td>\n",
       "      <td>0.852335</td>\n",
       "      <td>0.101152</td>\n",
       "      <td>7210040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.023916</td>\n",
       "      <td>0.797915</td>\n",
       "      <td>0.178169</td>\n",
       "      <td>7103890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.060225</td>\n",
       "      <td>0.541236</td>\n",
       "      <td>0.398539</td>\n",
       "      <td>7143442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010852</td>\n",
       "      <td>0.894415</td>\n",
       "      <td>0.094733</td>\n",
       "      <td>6860601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.964856</td>\n",
       "      <td>0.034633</td>\n",
       "      <td>6840081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100374</td>\n",
       "      <td>0.524810</td>\n",
       "      <td>0.374816</td>\n",
       "      <td>6922337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.032448</td>\n",
       "      <td>0.474580</td>\n",
       "      <td>0.492972</td>\n",
       "      <td>6913616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.123219</td>\n",
       "      <td>0.487968</td>\n",
       "      <td>0.388813</td>\n",
       "      <td>6937820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.209257</td>\n",
       "      <td>0.261908</td>\n",
       "      <td>0.528836</td>\n",
       "      <td>6893933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.027271</td>\n",
       "      <td>0.938227</td>\n",
       "      <td>0.034502</td>\n",
       "      <td>6832604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.161092</td>\n",
       "      <td>0.465898</td>\n",
       "      <td>0.373010</td>\n",
       "      <td>6915282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.013149</td>\n",
       "      <td>0.846270</td>\n",
       "      <td>0.140580</td>\n",
       "      <td>7127565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.008039</td>\n",
       "      <td>0.971180</td>\n",
       "      <td>0.020782</td>\n",
       "      <td>6827899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.992723</td>\n",
       "      <td>0.007084</td>\n",
       "      <td>6934855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.013998</td>\n",
       "      <td>0.783913</td>\n",
       "      <td>0.202089</td>\n",
       "      <td>6861826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.047073</td>\n",
       "      <td>0.542969</td>\n",
       "      <td>0.409957</td>\n",
       "      <td>6871643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.966663</td>\n",
       "      <td>0.031791</td>\n",
       "      <td>6842542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002329</td>\n",
       "      <td>0.957177</td>\n",
       "      <td>0.040494</td>\n",
       "      <td>6934145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.178802</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.405434</td>\n",
       "      <td>6829365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.123237</td>\n",
       "      <td>0.580077</td>\n",
       "      <td>0.296687</td>\n",
       "      <td>7167858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.007422</td>\n",
       "      <td>0.953844</td>\n",
       "      <td>0.038734</td>\n",
       "      <td>6859483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.055498</td>\n",
       "      <td>0.715903</td>\n",
       "      <td>0.228599</td>\n",
       "      <td>6861377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.043087</td>\n",
       "      <td>0.560059</td>\n",
       "      <td>0.396854</td>\n",
       "      <td>6848960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.002322</td>\n",
       "      <td>0.963215</td>\n",
       "      <td>0.034463</td>\n",
       "      <td>6918850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.188851</td>\n",
       "      <td>0.281547</td>\n",
       "      <td>0.529602</td>\n",
       "      <td>6916867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.011510</td>\n",
       "      <td>0.804200</td>\n",
       "      <td>0.184290</td>\n",
       "      <td>6895840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.457403</td>\n",
       "      <td>0.226384</td>\n",
       "      <td>0.316213</td>\n",
       "      <td>6813539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.046458</td>\n",
       "      <td>0.696346</td>\n",
       "      <td>0.257196</td>\n",
       "      <td>7116900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.037823</td>\n",
       "      <td>0.851685</td>\n",
       "      <td>0.110491</td>\n",
       "      <td>6890328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74629</th>\n",
       "      <td>0.144336</td>\n",
       "      <td>0.437690</td>\n",
       "      <td>0.417974</td>\n",
       "      <td>6855560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74630</th>\n",
       "      <td>0.316823</td>\n",
       "      <td>0.308862</td>\n",
       "      <td>0.374315</td>\n",
       "      <td>6816731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74631</th>\n",
       "      <td>0.038989</td>\n",
       "      <td>0.872955</td>\n",
       "      <td>0.088056</td>\n",
       "      <td>6925764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74632</th>\n",
       "      <td>0.007550</td>\n",
       "      <td>0.925330</td>\n",
       "      <td>0.067120</td>\n",
       "      <td>7139280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74633</th>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.714138</td>\n",
       "      <td>0.282172</td>\n",
       "      <td>6913068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74634</th>\n",
       "      <td>0.007719</td>\n",
       "      <td>0.961053</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>6828445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74635</th>\n",
       "      <td>0.071740</td>\n",
       "      <td>0.712201</td>\n",
       "      <td>0.216058</td>\n",
       "      <td>6867865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74636</th>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.954436</td>\n",
       "      <td>0.044282</td>\n",
       "      <td>6820397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74637</th>\n",
       "      <td>0.011347</td>\n",
       "      <td>0.908380</td>\n",
       "      <td>0.080273</td>\n",
       "      <td>6852197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74638</th>\n",
       "      <td>0.085755</td>\n",
       "      <td>0.391003</td>\n",
       "      <td>0.523241</td>\n",
       "      <td>7122934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74639</th>\n",
       "      <td>0.000113</td>\n",
       "      <td>0.949778</td>\n",
       "      <td>0.050110</td>\n",
       "      <td>6907838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74640</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.988173</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>6865896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74641</th>\n",
       "      <td>0.226819</td>\n",
       "      <td>0.242349</td>\n",
       "      <td>0.530832</td>\n",
       "      <td>6840250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74642</th>\n",
       "      <td>0.028187</td>\n",
       "      <td>0.757904</td>\n",
       "      <td>0.213909</td>\n",
       "      <td>6926011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74643</th>\n",
       "      <td>0.041050</td>\n",
       "      <td>0.836743</td>\n",
       "      <td>0.122208</td>\n",
       "      <td>6893100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74644</th>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.972452</td>\n",
       "      <td>0.027127</td>\n",
       "      <td>6867538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74645</th>\n",
       "      <td>0.271095</td>\n",
       "      <td>0.358729</td>\n",
       "      <td>0.370177</td>\n",
       "      <td>6884360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74646</th>\n",
       "      <td>0.209401</td>\n",
       "      <td>0.567487</td>\n",
       "      <td>0.223112</td>\n",
       "      <td>6903964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74647</th>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.684021</td>\n",
       "      <td>0.254391</td>\n",
       "      <td>6907851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74648</th>\n",
       "      <td>0.084404</td>\n",
       "      <td>0.483251</td>\n",
       "      <td>0.432345</td>\n",
       "      <td>7211166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74649</th>\n",
       "      <td>0.129933</td>\n",
       "      <td>0.459555</td>\n",
       "      <td>0.410512</td>\n",
       "      <td>6844290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74650</th>\n",
       "      <td>0.168160</td>\n",
       "      <td>0.465146</td>\n",
       "      <td>0.366694</td>\n",
       "      <td>6947597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74651</th>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.505695</td>\n",
       "      <td>0.494132</td>\n",
       "      <td>6895423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74652</th>\n",
       "      <td>0.009663</td>\n",
       "      <td>0.964584</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>6812077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74653</th>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.995000</td>\n",
       "      <td>0.004883</td>\n",
       "      <td>6903956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74654</th>\n",
       "      <td>0.020071</td>\n",
       "      <td>0.913397</td>\n",
       "      <td>0.066532</td>\n",
       "      <td>6881005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74655</th>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.995918</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>6835379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74656</th>\n",
       "      <td>0.064074</td>\n",
       "      <td>0.807041</td>\n",
       "      <td>0.128885</td>\n",
       "      <td>6882352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74657</th>\n",
       "      <td>0.223933</td>\n",
       "      <td>0.428509</td>\n",
       "      <td>0.347558</td>\n",
       "      <td>6884758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74658</th>\n",
       "      <td>0.044476</td>\n",
       "      <td>0.749553</td>\n",
       "      <td>0.205970</td>\n",
       "      <td>6924212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74659 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           high       low    medium  listing_id\n",
       "0      0.060949  0.548982  0.390068     7142618\n",
       "1      0.046513  0.852335  0.101152     7210040\n",
       "2      0.023916  0.797915  0.178169     7103890\n",
       "3      0.060225  0.541236  0.398539     7143442\n",
       "4      0.010852  0.894415  0.094733     6860601\n",
       "5      0.000511  0.964856  0.034633     6840081\n",
       "6      0.100374  0.524810  0.374816     6922337\n",
       "7      0.032448  0.474580  0.492972     6913616\n",
       "8      0.123219  0.487968  0.388813     6937820\n",
       "9      0.209257  0.261908  0.528836     6893933\n",
       "10     0.027271  0.938227  0.034502     6832604\n",
       "11     0.161092  0.465898  0.373010     6915282\n",
       "12     0.013149  0.846270  0.140580     7127565\n",
       "13     0.008039  0.971180  0.020782     6827899\n",
       "14     0.000194  0.992723  0.007084     6934855\n",
       "15     0.013998  0.783913  0.202089     6861826\n",
       "16     0.047073  0.542969  0.409957     6871643\n",
       "17     0.001546  0.966663  0.031791     6842542\n",
       "18     0.002329  0.957177  0.040494     6934145\n",
       "19     0.178802  0.415764  0.405434     6829365\n",
       "20     0.123237  0.580077  0.296687     7167858\n",
       "21     0.007422  0.953844  0.038734     6859483\n",
       "22     0.055498  0.715903  0.228599     6861377\n",
       "23     0.043087  0.560059  0.396854     6848960\n",
       "24     0.002322  0.963215  0.034463     6918850\n",
       "25     0.188851  0.281547  0.529602     6916867\n",
       "26     0.011510  0.804200  0.184290     6895840\n",
       "27     0.457403  0.226384  0.316213     6813539\n",
       "28     0.046458  0.696346  0.257196     7116900\n",
       "29     0.037823  0.851685  0.110491     6890328\n",
       "...         ...       ...       ...         ...\n",
       "74629  0.144336  0.437690  0.417974     6855560\n",
       "74630  0.316823  0.308862  0.374315     6816731\n",
       "74631  0.038989  0.872955  0.088056     6925764\n",
       "74632  0.007550  0.925330  0.067120     7139280\n",
       "74633  0.003690  0.714138  0.282172     6913068\n",
       "74634  0.007719  0.961053  0.031227     6828445\n",
       "74635  0.071740  0.712201  0.216058     6867865\n",
       "74636  0.001282  0.954436  0.044282     6820397\n",
       "74637  0.011347  0.908380  0.080273     6852197\n",
       "74638  0.085755  0.391003  0.523241     7122934\n",
       "74639  0.000113  0.949778  0.050110     6907838\n",
       "74640  0.000206  0.988173  0.011620     6865896\n",
       "74641  0.226819  0.242349  0.530832     6840250\n",
       "74642  0.028187  0.757904  0.213909     6926011\n",
       "74643  0.041050  0.836743  0.122208     6893100\n",
       "74644  0.000422  0.972452  0.027127     6867538\n",
       "74645  0.271095  0.358729  0.370177     6884360\n",
       "74646  0.209401  0.567487  0.223112     6903964\n",
       "74647  0.061587  0.684021  0.254391     6907851\n",
       "74648  0.084404  0.483251  0.432345     7211166\n",
       "74649  0.129933  0.459555  0.410512     6844290\n",
       "74650  0.168160  0.465146  0.366694     6947597\n",
       "74651  0.000173  0.505695  0.494132     6895423\n",
       "74652  0.009663  0.964584  0.025753     6812077\n",
       "74653  0.000117  0.995000  0.004883     6903956\n",
       "74654  0.020071  0.913397  0.066532     6881005\n",
       "74655  0.000049  0.995918  0.004033     6835379\n",
       "74656  0.064074  0.807041  0.128885     6882352\n",
       "74657  0.223933  0.428509  0.347558     6884758\n",
       "74658  0.044476  0.749553  0.205970     6924212\n",
       "\n",
       "[74659 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_frame = pd.DataFrame(test_predict)\n",
    "result_frame.columns = le.classes_\n",
    "result_frame['listing_id'] = test.listing_id.reset_index().listing_id\n",
    "result_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Not submitted\n",
    "result_frame[['listing_id','high','medium','low']].to_csv('Photos-result.csv', \\\n",
    "                                                          index = False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
