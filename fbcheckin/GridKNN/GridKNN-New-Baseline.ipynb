{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['x','y','hour','weekday','day','month','year', 'accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, n_cell_x, n_cell_y):\n",
    "    #Creating the grid\n",
    "    size_x = 10. / n_cell_x\n",
    "    size_y = 10. / n_cell_y\n",
    "    eps = 0.00001  \n",
    "    xs = np.where(df.x.values < eps, 0, df.x.values - eps)\n",
    "    ys = np.where(df.y.values < eps, 0, df.y.values - eps)\n",
    "    pos_x = (xs / size_x).astype(np.int)\n",
    "    pos_y = (ys / size_y).astype(np.int)\n",
    "    df['grid_x'] = pos_x\n",
    "    df['grid_y'] = pos_y\n",
    "    \n",
    "    #Feature engineering\n",
    "    fw = [400, 1000, 4, 3.5, 1./22., 2, 9, 0.09] #feature weights (black magic here)\n",
    "    df.x = df.x.values * fw[0]\n",
    "    df.y = df.y.values * fw[1]\n",
    "    initial_date = np.datetime64('2014-01-01T01:01', dtype='datetime64[m]') \n",
    "    d_times = pd.DatetimeIndex(initial_date + np.timedelta64(int(mn), 'm') \n",
    "                               for mn in df.time.values)    \n",
    "    df['hour'] = (d_times.hour+ d_times.minute/60) * fw[2]\n",
    "    df['weekday'] = d_times.weekday * fw[3]\n",
    "    df['day'] = (d_times.dayofyear * fw[4]).astype(int)\n",
    "    df['month'] = d_times.month * fw[5]\n",
    "    df['year'] = (d_times.year - 2013) * fw[6]\n",
    "    df.accuracy = df.accuracy.values * fw[7]\n",
    "    df = df.drop(['time'], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_prediction(df_train, df_test, n_cell_x, n_cell_y, th):\n",
    "    total_result = pd.DataFrame()\n",
    "    for x_grid in range(0, n_cell_x):\n",
    "        start_time = time.time()\n",
    "        for y_grid in range(0, n_cell_y):\n",
    "            total_result = total_result.append(process_one_cell(df_train, df_test, x_grid, y_grid, th))\n",
    "        print(\"Elapsed time overall: %s seconds\" % (time.time() - start_time), x_grid, flush = True)\n",
    "    return total_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_one_cell(df_train, df_test, grid_x, grid_y, th):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df_cell_train = df_train[((df_train.grid_x == grid_x)&(df_train.grid_y == grid_y)) |\n",
    "                             ((df_train.grid_x == grid_x)&(df_train.grid_y == grid_y + 1)) |\n",
    "                             ((df_train.grid_x == grid_x)&(df_train.grid_y == grid_y - 1)) |\n",
    "                             ((df_train.grid_x == grid_x + 1)&(df_train.grid_y == grid_y)) |\n",
    "                             ((df_train.grid_x == grid_x + 1)&(df_train.grid_y == grid_y + 1)) |\n",
    "                             ((df_train.grid_x == grid_x + 1)&(df_train.grid_y == grid_y - 1)) |\n",
    "                             ((df_train.grid_x == grid_x - 1)&(df_train.grid_y == grid_y)) |\n",
    "                             ((df_train.grid_x == grid_x - 1)&(df_train.grid_y == grid_y + 1)) |\n",
    "                             ((df_train.grid_x == grid_x - 1)&(df_train.grid_y == grid_y - 1))]\n",
    "    place_counts = df_cell_train.place_id.value_counts()\n",
    "    mask = (place_counts[df_cell_train.place_id.values] >= th).values\n",
    "    df_cell_train = df_cell_train.loc[mask]\n",
    "    \n",
    "    df_cell_test = df_test[(df_test.grid_x == grid_x)&(df_test.grid_y == grid_y)]\n",
    "    row_ids = df_cell_test.row_id\n",
    "    \n",
    "    #Applying the classifier\n",
    "    clf = KNeighborsClassifier(n_neighbors=35, weights='distance', \n",
    "                               metric='manhattan')\n",
    "    clf.fit(df_cell_train[feature_list], df_cell_train.place_id)\n",
    "    predictions = clf.predict_proba(df_cell_test[feature_list])\n",
    "    result_index = np.argsort(predictions, axis=1)[:,::-1][:,:3]\n",
    "    result = pd.DataFrame(df_cell_test.row_id)\n",
    "    result['p1'] = clf.classes_[result_index][:,:1]\n",
    "    result['p2'] = clf.classes_[result_index][:,1:2]\n",
    "    result['p3'] = clf.classes_[result_index][:,2:3]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train data\n",
      "Elapsed time overall: 106.98082089424133 seconds 0\n",
      "Elapsed time overall: 118.86453318595886 seconds 1\n",
      "Elapsed time overall: 117.29410934448242 seconds 2\n",
      "Elapsed time overall: 116.85728001594543 seconds 3\n",
      "Elapsed time overall: 118.99973654747009 seconds 4\n",
      "Elapsed time overall: 121.4804277420044 seconds 5\n",
      "Elapsed time overall: 123.10025262832642 seconds 6\n",
      "Elapsed time overall: 121.18829846382141 seconds 7\n",
      "Elapsed time overall: 131.77376413345337 seconds 8\n",
      "Elapsed time overall: 139.89727544784546 seconds 9\n",
      "Elapsed time overall: 126.47413969039917 seconds 10\n",
      "Elapsed time overall: 122.64227390289307 seconds 11\n",
      "Elapsed time overall: 135.5942394733429 seconds 12\n",
      "Elapsed time overall: 135.70360040664673 seconds 13\n",
      "Elapsed time overall: 123.13283133506775 seconds 14\n",
      "Elapsed time overall: 124.91680526733398 seconds 15\n",
      "Elapsed time overall: 122.79931306838989 seconds 16\n",
      "Elapsed time overall: 122.99077367782593 seconds 17\n",
      "Elapsed time overall: 131.9342110157013 seconds 18\n",
      "Elapsed time overall: 138.6922414302826 seconds 19\n",
      "Elapsed time overall: 143.21623301506042 seconds 20\n",
      "Elapsed time overall: 155.26330828666687 seconds 21\n",
      "Elapsed time overall: 139.29722332954407 seconds 22\n",
      "Elapsed time overall: 138.42507147789001 seconds 23\n",
      "Elapsed time overall: 139.06821060180664 seconds 24\n",
      "Elapsed time overall: 138.52488136291504 seconds 25\n",
      "Elapsed time overall: 138.6746768951416 seconds 26\n",
      "Elapsed time overall: 154.08312821388245 seconds 27\n",
      "Elapsed time overall: 136.8782458305359 seconds 28\n",
      "Elapsed time overall: 144.0262484550476 seconds 29\n"
     ]
    }
   ],
   "source": [
    "# Run validation\n",
    "df_train = pd.read_csv('../train.csv',\n",
    "                           usecols=['row_id','x','y','accuracy','time','place_id'])\n",
    "\n",
    "df_valiation = df_train[df_train.time > 786239 * 0.875]\n",
    "\n",
    "df_train = df_train[df_train.time <= 786239 * 0.875]\n",
    "\n",
    "n_cell_x = 30\n",
    "n_cell_y = 60 \n",
    "\n",
    "print('Preparing train data')\n",
    "df_train = prepare_data(df_train, n_cell_x, n_cell_y)\n",
    "df_valiation = prepare_data(df_valiation, n_cell_x, n_cell_y)\n",
    "df_valiation['p1'] = np.nan\n",
    "df_valiation['p2'] = np.nan\n",
    "df_valiation['p3'] = np.nan\n",
    "\n",
    "prediction_result = run_prediction(df_train, df_valiation, n_cell_x, n_cell_y, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4417684.000000\n",
       "mean           0.540568\n",
       "std            0.451199\n",
       "min            0.000000\n",
       "25%            0.000000\n",
       "50%            0.500000\n",
       "75%            1.000000\n",
       "max            1.000000\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate score\n",
    "prediction_result.sort_index(inplace=True)\n",
    "prediction_result['score'] = (prediction_result.p1 == df_valiation.place_id) * 1\n",
    "prediction_result['score'] += (prediction_result.p2 == df_valiation.place_id) * 0.5\n",
    "prediction_result['score'] += (prediction_result.p3 == df_valiation.place_id) * 0.33\n",
    "\n",
    "prediction_result.score.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write to file\n",
    "prediction_result['place_id'] = prediction_result.p1.astype(str) + \" \" + \\\n",
    "                                 prediction_result.p2.astype(str) + \" \" + \\\n",
    "                                 prediction_result.p3.astype(str)\n",
    "prediction_result[['row_id', 'place_id']].to_csv('new_baseline_validation_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time overall: 176.69736409187317 seconds 0\n",
      "Elapsed time overall: 182.33909511566162 seconds 1\n",
      "Elapsed time overall: 179.95632672309875 seconds 2\n",
      "Elapsed time overall: 194.7431447505951 seconds 3\n",
      "Elapsed time overall: 195.13991928100586 seconds 4\n",
      "Elapsed time overall: 194.94174075126648 seconds 5\n",
      "Elapsed time overall: 202.69043922424316 seconds 6\n",
      "Elapsed time overall: 201.27015614509583 seconds 7\n",
      "Elapsed time overall: 199.84535193443298 seconds 8\n",
      "Elapsed time overall: 188.66247296333313 seconds 9\n",
      "Elapsed time overall: 187.3608193397522 seconds 10\n",
      "Elapsed time overall: 210.6493799686432 seconds 11\n",
      "Elapsed time overall: 188.98353624343872 seconds 12\n",
      "Elapsed time overall: 209.71220684051514 seconds 13\n",
      "Elapsed time overall: 198.13238406181335 seconds 14\n",
      "Elapsed time overall: 194.97281408309937 seconds 15\n",
      "Elapsed time overall: 191.00574207305908 seconds 16\n",
      "Elapsed time overall: 196.04477214813232 seconds 17\n",
      "Elapsed time overall: 206.2481746673584 seconds 18\n",
      "Elapsed time overall: 192.09367036819458 seconds 19\n",
      "Elapsed time overall: 230.22386527061462 seconds 20\n",
      "Elapsed time overall: 240.7894356250763 seconds 21\n",
      "Elapsed time overall: 204.11408138275146 seconds 22\n",
      "Elapsed time overall: 210.8677315711975 seconds 23\n",
      "Elapsed time overall: 218.96578240394592 seconds 24\n",
      "Elapsed time overall: 201.92732858657837 seconds 25\n",
      "Elapsed time overall: 216.52170586585999 seconds 26\n",
      "Elapsed time overall: 206.87710118293762 seconds 27\n",
      "Elapsed time overall: 203.89530777931213 seconds 28\n",
      "Elapsed time overall: 193.16619753837585 seconds 29\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "df_train = pd.read_csv('../train.csv',\n",
    "                       usecols=['row_id','x','y','accuracy','time','place_id'])\n",
    "df_test = pd.read_csv('../test.csv',\n",
    "                       usecols=['row_id','x','y','accuracy','time'])\n",
    "n_cell_x = 30\n",
    "n_cell_y = 60 \n",
    "\n",
    "df_train = prepare_data(df_train, n_cell_x, n_cell_y)\n",
    "df_test = prepare_data(df_test, n_cell_x, n_cell_y)\n",
    "df_test['p1'] = np.nan\n",
    "df_test['p2'] = np.nan\n",
    "df_test['p3'] = np.nan\n",
    "prediction_result = run_prediction(df_train, df_test, 5)\n",
    "\n",
    "prediction_result.sort_index(inplace=True)\n",
    "prediction_result['place_id'] = prediction_result.p1.astype(str) + \" \" + \\\n",
    "                                 prediction_result.p2.astype(str) + \" \" + \\\n",
    "                                 prediction_result.p3.astype(str)\n",
    "prediction_result[['row_id', 'place_id']].to_csv('new_baseline_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
